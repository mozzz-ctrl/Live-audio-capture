<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Live Microphone Audio Streaming with Noise Suppression</title>
  <style>
    #visualizer {
      width: 300px;
      height: 50px;
      background-color: #222;
      border-radius: 5px;
      margin-top: 20px;
      display: block;
    }
    #noiseLevel {
      margin-top: 10px;
      font-family: monospace;
      color: #0f0;
    }
  </style>
</head>
<body>
  <h2>Live Microphone Audio Streaming with Noise Level & Background Noise Removal</h2>

  <button id="startBtn">Start Streaming</button>
  <button id="stopBtn" disabled>Stop Streaming</button>

  <canvas id="visualizer" width="300" height="50"></canvas>
  <div id="noiseLevel">Noise Level: N/A</div>

  <script>
    let audioContext;
    let mediaStream;
    let sourceNode;
    let analyser;
    let animationId;

    const startBtn = document.getElementById('startBtn');
    const stopBtn = document.getElementById('stopBtn');
    const canvas = document.getElementById('visualizer');
    const canvasCtx = canvas.getContext('2d');
    const noiseLevelDisplay = document.getElementById('noiseLevel');

    async function startStreaming() {
      if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        alert('Your browser does not support audio streaming.');
        return;
      }
      try {
        audioContext = new AudioContext();

        // Enable noise suppression via constraints
        mediaStream = await navigator.mediaDevices.getUserMedia({ 
          audio: { noiseSuppression: true } 
        });

        sourceNode = audioContext.createMediaStreamSource(mediaStream);
        analyser = audioContext.createAnalyser();
        analyser.fftSize = 256;

        sourceNode.connect(analyser);
        analyser.connect(audioContext.destination);

        startBtn.disabled = true;
        stopBtn.disabled = false;

        visualize();
      } catch (err) {
        alert('Error accessing microphone: ' + err.message);
      }
    }

    function stopStreaming() {
      if (mediaStream) {
        mediaStream.getTracks().forEach(track => track.stop());
      }
      if (sourceNode) {
        sourceNode.disconnect();
      }
      if (analyser) {
        analyser.disconnect();
      }
      if (audioContext) {
        audioContext.close();
      }
      cancelAnimationFrame(animationId);

      canvasCtx.clearRect(0, 0, canvas.width, canvas.height);
      noiseLevelDisplay.textContent = 'Noise Level: N/A';

      startBtn.disabled = false;
      stopBtn.disabled = true;
    }

    function visualize() {
      const bufferLength = analyser.frequencyBinCount;
      const dataArray = new Uint8Array(bufferLength);

      function draw() {
        animationId = requestAnimationFrame(draw);

        analyser.getByteFrequencyData(dataArray);

        // Clear background
        canvasCtx.fillStyle = '#222';
        canvasCtx.fillRect(0, 0, canvas.width, canvas.height);

        const barWidth = (canvas.width / bufferLength) * 2.5;
        let barHeight;
        let x = 0;

        let sum = 0;
        for(let i = 0; i < bufferLength; i++) {
          barHeight = dataArray[i] / 2;
          sum += dataArray[i];

          canvasCtx.fillStyle = 'lime';
          canvasCtx.fillRect(x, canvas.height - barHeight, barWidth, barHeight);

          x += barWidth + 1;
        }
        const avg = sum / bufferLength;
        noiseLevelDisplay.textContent = 'Noise Level: ' + avg.toFixed(2);
      }

      draw();
    }

    startBtn.addEventListener('click', startStreaming);
    stopBtn.addEventListener('click', stopStreaming);

    // Attempt to auto start on page load (may require user interaction)
    window.addEventListener('DOMContentLoaded', () => {
      setTimeout(() => {
        startStreaming();
      }, 500);
    });
  </script>
</body>
</html>
